{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"feature_extraction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPuxgPmMOZwh82Nb4CNsRUm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ylv3VBMHA_hu"},"source":["## **Imports**"]},{"cell_type":"code","metadata":{"id":"0JIWi4hbZfiX","executionInfo":{"status":"ok","timestamp":1624431391846,"user_tz":-120,"elapsed":489,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}}},"source":["# import the necessary packages\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.image import load_img\n","\n","from google.colab import drive\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","import cv2\n","import random\n","import sys\n","import os\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kPKVHVBsOOX3","executionInfo":{"status":"ok","timestamp":1624431392269,"user_tz":-120,"elapsed":19,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}},"outputId":"63253b81-3a5b-47eb-f8c4-f984ff59c621"},"source":["# mount drive folder and import custom modules\n","drive.mount('/content/drive', force_remount=False)\n","sys.path.insert(0,'/content/drive/MyDrive/Shark_Classification')\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-XJsG-HIGkdZ"},"source":["## **Loag VGG Net**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05I4lDdaG1ic","executionInfo":{"status":"ok","timestamp":1624431392271,"user_tz":-120,"elapsed":17,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}},"outputId":"e85344a7-7903-4c1e-d30a-1a35c81cfa45"},"source":["# load the VGG16 network and initialize the label encoder\n","print(\"[INFO] loading network...\")\n","model = VGG16(weights=\"imagenet\", include_top=False)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[INFO] loading network...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BeaeP3A5BLOT"},"source":["## **Function to List Files in Directory**"]},{"cell_type":"code","metadata":{"id":"M1EjaMbMTksF","executionInfo":{"status":"ok","timestamp":1624431392272,"user_tz":-120,"elapsed":13,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}}},"source":["file_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n","keep_labels     = ['great_white_shark','hammerhead_shark']\n","\n","def list_files(indir=os.getcwd(),valid_extensions=file_extensions,valid_labels=keep_labels):\n","    for (rootdir,dirs,files) in os.walk(indir):\n","        for filename in files:\n","            # determine the file extension of the current file\n","            ext = filename[filename.rfind(\".\"):].lower()\n","            \n","            # check to see if the file is an image and should be processed\n","            if valid_extensions is None or ext.endswith(valid_extensions):\n","                \n","                # construct the path to the image and yield it\n","                imagePath = os.path.join(rootdir, filename)\n","                \n","                # yield the path if the label should not be dropped \n","                if imagePath.split(os.path.sep)[-2] in valid_labels:\n","                    yield imagePath\n","            \n","    return"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N7Lt0SwuBc28"},"source":["## **Read Files**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QW1DPwj5BcCL","executionInfo":{"status":"ok","timestamp":1624431392771,"user_tz":-120,"elapsed":511,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}},"outputId":"163485dd-5042-481b-c228-e44da043f3d3"},"source":["dataset_path = os.path.join(sys.path[0],'sharks')\n","output_path= os.path.join(sys.path[0],\"output\")\n","    \n","#obtain image paths and ramdomize it\n","image_paths = list(list_files(dataset_path))\n","random.seed(42)\n","random.shuffle(image_paths)\n","    \n","# initialize data and labels list\n","data, labels, count = [],[],0\n","\n","# preparing labels  \n","for i in image_paths:       \n","    label = i.split(os.path.sep)[-2]\n","    labels.append(label)\n","\n","# print label count\n","label_list = os.listdir(dataset_path)\n","for l in label_list: print(\"label: {} counts: {}\".format(l,labels.count(l)))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["label: great_white_shark counts: 928\n","label: mako counts: 0\n","label: tiger_shark counts: 0\n","label: hammerhead_shark counts: 744\n","label: whale_shark counts: 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C14qc_v-CB60"},"source":["## **Data Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"Gqs_p_mLECnW"},"source":["### **Train/Test Split**"]},{"cell_type":"code","metadata":{"id":"foIklGOKEDFg","executionInfo":{"status":"ok","timestamp":1624431392773,"user_tz":-120,"elapsed":14,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}}},"source":["# partition the data into training and testing splits using 75% of\n","# the data for training and the remaining 25% for testing\n","test_size = 0.25\n","isplit = int(len(labels)*(1-test_size))\n","\n","Labels = [labels[:isplit], labels[isplit:]]\n","Paths  = [image_paths[:isplit],image_paths[isplit:]]\n","Split  = [\"train\",\"val\"]\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lj6w2w6HZPje"},"source":["### **Read and Preprocess Image Function**"]},{"cell_type":"code","metadata":{"id":"ugWNVQSbYvfn","executionInfo":{"status":"ok","timestamp":1624431392775,"user_tz":-120,"elapsed":13,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}}},"source":["def read_and_preprocess(path):\n","  image = load_img(path, target_size=(224, 224))\n","  image = img_to_array(image)\n","  image = np.expand_dims(image, axis=0)\n","  image = preprocess_input(image)\n","  return image\n"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"poZi6nMsq6Iu"},"source":["##**Perform Feature Extraction**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"811n0SthNijk","executionInfo":{"status":"ok","timestamp":1624431458954,"user_tz":-120,"elapsed":66191,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}},"outputId":"8dda4fab-0eb2-4d3c-e915-42ae20238bda"},"source":["# initialize label encoder and batch size\n","BS =32\n","le = None\n","Features = {}\n","\n","# loop over the possible dataset splits\n","for (s,split) in enumerate(Split):\n","  labels    = Labels[s]\n","  img_paths = Paths[s]\n","  Features[split+\"X\"] = []\n","  Features[split+\"Y\"] = []\n","\n","  # if the label encoder is None, create it\n","  if le is None:\n","    le = LabelEncoder()\n","    le.fit(labels)\n","\t\n","  # open the output CSV file for writing\n","  csvPath = os.path.sep.join([output_path,\"{}.csv\".format(split)])\n","  csv = open(csvPath, \"w\")\n"," \n","  # loop over the images in batches\n","  for (b, i) in enumerate(range(0, len(img_paths), BS)):\n","    \n","    # extract the batch of images and labels, then initialize the\n","    # list of actual images that will be passed through the network\n","    # for feature extraction\n","    print(\"[INFO] processing batch {}/{}\".format(b + 1, int(np.ceil(len(img_paths) / float(BS)))))\n","    batchPaths = img_paths[i:i + BS]\n","    batchLabels = le.transform(labels[i:i + BS])\n","    \n","    # loop over the images and labels in the current batch\n","    # add the preprocessed image to the batch\n","    batchImages = []\n","    for imagePath in batchPaths: batchImages.append(read_and_preprocess(imagePath))\n","\n","    # pass the images through the network and use the outputs as\n","    # our actual features, then reshape the features into a\n","    # flattened volume\n","    batchImages = np.vstack(batchImages)\n","    features = model.predict(batchImages, batch_size=BS)\n","    features = features.reshape((features.shape[0], 7 * 7 * 512))\n","\n","    # loop over the class labels and extracted features\n","    for (label, vec) in zip(batchLabels, features):\n","\n","      # append feature vector and labels\n","      Features[split+\"X\"].append(vec)\n","      Features[split+\"Y\"].append(label)\n","\n","      # construct a row that exists of the class label and\n","      # extracted features\n","      vec = \",\".join([str(v) for v in vec])\n","      csv.write(\"{},{}\\n\".format(label, vec))\n","\n","  # close the CSV file\n","  csv.close()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[INFO] processing batch 1/40\n","[INFO] processing batch 2/40\n","[INFO] processing batch 3/40\n","[INFO] processing batch 4/40\n","[INFO] processing batch 5/40\n","[INFO] processing batch 6/40\n","[INFO] processing batch 7/40\n","[INFO] processing batch 8/40\n","[INFO] processing batch 9/40\n","[INFO] processing batch 10/40\n","[INFO] processing batch 11/40\n","[INFO] processing batch 12/40\n","[INFO] processing batch 13/40\n","[INFO] processing batch 14/40\n","[INFO] processing batch 15/40\n","[INFO] processing batch 16/40\n","[INFO] processing batch 17/40\n","[INFO] processing batch 18/40\n","[INFO] processing batch 19/40\n","[INFO] processing batch 20/40\n","[INFO] processing batch 21/40\n","[INFO] processing batch 22/40\n","[INFO] processing batch 23/40\n","[INFO] processing batch 24/40\n","[INFO] processing batch 25/40\n","[INFO] processing batch 26/40\n","[INFO] processing batch 27/40\n","[INFO] processing batch 28/40\n","[INFO] processing batch 29/40\n","[INFO] processing batch 30/40\n","[INFO] processing batch 31/40\n","[INFO] processing batch 32/40\n","[INFO] processing batch 33/40\n","[INFO] processing batch 34/40\n","[INFO] processing batch 35/40\n","[INFO] processing batch 36/40\n","[INFO] processing batch 37/40\n","[INFO] processing batch 38/40\n","[INFO] processing batch 39/40\n","[INFO] processing batch 40/40\n","[INFO] processing batch 1/14\n","[INFO] processing batch 2/14\n","[INFO] processing batch 3/14\n","[INFO] processing batch 4/14\n","[INFO] processing batch 5/14\n","[INFO] processing batch 6/14\n","[INFO] processing batch 7/14\n","[INFO] processing batch 8/14\n","[INFO] processing batch 9/14\n","[INFO] processing batch 10/14\n","[INFO] processing batch 11/14\n","[INFO] processing batch 12/14\n","[INFO] processing batch 13/14\n","[INFO] processing batch 14/14\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d4raNKDSGOjT"},"source":["##**Save the Label Encoder**"]},{"cell_type":"code","metadata":{"id":"FDWF_jk3cGzC","executionInfo":{"status":"ok","timestamp":1624431458956,"user_tz":-120,"elapsed":29,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}}},"source":["le_path=os.path.join(output_path, \"le.cpickle\")\n","\n","# serialize the label encoder to disk\n","f = open(le_path, \"wb\")\n","f.write(pickle.dumps(le))\n","f.close()"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Gu4HIzckwHK"},"source":["##**Train a Logistig Regression on features**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-VAhf4NkJPf","executionInfo":{"status":"ok","timestamp":1624431464501,"user_tz":-120,"elapsed":5570,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}},"outputId":"59375b78-8878-4e9c-9411-f8eb1e10b614"},"source":["trainX = np.array(Features[\"trainX\"])\n","trainY = np.array(Features[\"trainY\"])\n","testX  = np.array(Features[\"valX\"])\n","testY  = np.array(Features[\"valY\"])\n","\n","# train the model\n","print(\"[INFO] training model...\")\n","model = LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\",max_iter=150)\n","model.fit(trainX, trainY)\n","\n","# evaluate the model\n","print(\"[INFO] evaluating...\")\n","preds = model.predict(testX)\n","print(classification_report(testY, preds, target_names=le.classes_))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["[INFO] training model...\n","[INFO] evaluating...\n","                   precision    recall  f1-score   support\n","\n","great_white_shark       1.00      0.97      0.98       225\n"," hammerhead_shark       0.97      0.99      0.98       193\n","\n","         accuracy                           0.98       418\n","        macro avg       0.98      0.98      0.98       418\n","     weighted avg       0.98      0.98      0.98       418\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EMnauEDeqbFC"},"source":["##**Save the model**\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6l53GMPqYhP","executionInfo":{"status":"ok","timestamp":1624431960873,"user_tz":-120,"elapsed":882,"user":{"displayName":"Giulio Grossi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFVykiMSdOmcDO7YoergNBa6Y1rS9VjBTOxY1H=s64","userId":"07242043426658042352"}},"outputId":"74c031a7-0261-44c9-9845-138fdafe357f"},"source":["save=True\n","modelPath = os.path.sep.join([output_path,\"vggnet_transfer_model.cpickle\"])\n","\n","if save:\n","  # serialize the model to disk\n","  print(\"[INFO] saving model...\")\n","  f = open(modelPath, \"wb\")\n","  f.write(pickle.dumps(model))\n","  f.close()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[INFO] saving model...\n"],"name":"stdout"}]}]}